{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIw7ddjLnE4c"
      },
      "source": [
        "# Listen to some samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:39.876842Z",
          "iopub.status.busy": "2022-05-02T12:21:39.876566Z",
          "iopub.status.idle": "2022-05-02T12:21:39.890987Z",
          "shell.execute_reply": "2022-05-02T12:21:39.890224Z",
          "shell.execute_reply.started": "2022-05-02T12:21:39.876815Z"
        },
        "id": "eVDUeEemnE4j",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "rate must be specified when data is a numpy array or list of audio samples.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mipd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m ipd\u001b[39m.\u001b[39;49mAudio(\u001b[39m\"\u001b[39;49m\u001b[39m../input/clean-data/clean_trainset_28spk_wav/p226_001.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/lib/display.py:129\u001b[0m, in \u001b[0;36mAudio.__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay, normalize, element_id)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m rate \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mrate must be specified when data is a numpy array or list of audio samples.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m Audio\u001b[39m.\u001b[39m_make_wav(data, rate, normalize)\n",
            "\u001b[0;31mValueError\u001b[0m: rate must be specified when data is a numpy array or list of audio samples."
          ]
        }
      ],
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "\n",
        "ipd.Audio(\"../input/clean-data/clean_trainset_28spk_wav/p226_001.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:40.203877Z",
          "iopub.status.busy": "2022-05-02T12:21:40.203423Z",
          "iopub.status.idle": "2022-05-02T12:21:40.215662Z",
          "shell.execute_reply": "2022-05-02T12:21:40.214805Z",
          "shell.execute_reply.started": "2022-05-02T12:21:40.203827Z"
        },
        "id": "9-Mx4WB_nE4o",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "\n",
        "ipd.Audio(\"../input/noisy-data/noisy_trainset_28spk_wav/p226_001.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-AMjf0fnE4s"
      },
      "source": [
        "# Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:40.487172Z",
          "iopub.status.busy": "2022-05-02T12:21:40.486697Z",
          "iopub.status.idle": "2022-05-02T12:21:40.541571Z",
          "shell.execute_reply": "2022-05-02T12:21:40.54094Z",
          "shell.execute_reply.started": "2022-05-02T12:21:40.487122Z"
        },
        "id": "som3HIpAnE4v",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clean samples:  2570\n",
            "Number of noisy samples:  2570\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "clean_wavs_path = glob.glob('./data/clear_samples/*.wav')\n",
        "noisy_wavs_path = glob.glob('./data/noisy_samples/*.wav')\n",
        "\n",
        "# print the number of samples\n",
        "print('Number of clean samples: ', len(clean_wavs_path))\n",
        "print('Number of noisy samples: ', len(noisy_wavs_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:41.248333Z",
          "iopub.status.busy": "2022-05-02T12:21:41.247796Z",
          "iopub.status.idle": "2022-05-02T12:21:41.253485Z",
          "shell.execute_reply": "2022-05-02T12:21:41.252512Z",
          "shell.execute_reply.started": "2022-05-02T12:21:41.248298Z"
        },
        "id": "gd8ECSJXnE4y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "    target_sample_rate=48000\n",
        "    duration=4\n",
        "    n_fft=1024\n",
        "    hop_length=512\n",
        "    n_mels=64\n",
        "    batch_size=128\n",
        "    learning_rate=1e-6\n",
        "    epochs=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:41.496875Z",
          "iopub.status.busy": "2022-05-02T12:21:41.496601Z",
          "iopub.status.idle": "2022-05-02T12:21:41.513045Z",
          "shell.execute_reply": "2022-05-02T12:21:41.512352Z",
          "shell.execute_reply.started": "2022-05-02T12:21:41.496846Z"
        },
        "id": "wKUpg74qnE41",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, clean_data_path, noisy_data_path, transform=None,\n",
        "                 target_sample_rate=config.target_sample_rate, duration=config.duration):\n",
        "        self.root_clean = clean_data_path\n",
        "        self.root_noisy = noisy_data_path\n",
        "        self.transform = transform\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        self.num_samples = target_sample_rate*duration\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.root_clean)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        audio_path_clean = self.root_clean[index]\n",
        "        audio_path_noisy = self.root_noisy[index]\n",
        "        \n",
        "        signal, sr = torchaudio.load(audio_path_clean)\n",
        "        signal_noisy, sr_noisy = torchaudio.load(audio_path_noisy)\n",
        "        if sr != self.target_sample_rate:\n",
        "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
        "            signal = resampler(signal)\n",
        "            signal_noisy = resampler(signal_noisy)\n",
        "        \n",
        "        if signal.shape[0] > 1:\n",
        "            signal = torch.mean(signal, axis=0, keepdim=True)\n",
        "        \n",
        "        if signal_noisy.shape[0] > 1:\n",
        "            signal_noisy = torch.mean(signal_noisy, axis=0, keepdim=True)\n",
        "        \n",
        "        if signal.shape[1] > self.num_samples:\n",
        "            signal = signal[:, :self.num_samples]\n",
        "            \n",
        "        if signal_noisy.shape[1] > self.num_samples:\n",
        "            signal_noisy = signal_noisy[:, :self.num_samples]\n",
        "        \n",
        "        if signal.shape[1] < self.num_samples:\n",
        "            num_missing_samples = self.num_samples - signal.shape[1]\n",
        "            signal = F.pad(signal, (0, num_missing_samples))\n",
        "            \n",
        "        if signal_noisy.shape[1] < self.num_samples:\n",
        "            num_missing_samples = self.num_samples - signal_noisy.shape[1]\n",
        "            signal_noisy = F.pad(signal_noisy, (0, num_missing_samples))\n",
        "        \n",
        "        mel = self.transform(signal)\n",
        "        mel_noisy = self.transform(signal_noisy)\n",
        "        #print(mel.shape)\n",
        "        image = mel / torch.abs(mel).max()\n",
        "        return mel, mel_noisy#, signal_noisy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:41.739127Z",
          "iopub.status.busy": "2022-05-02T12:21:41.738833Z",
          "iopub.status.idle": "2022-05-02T12:21:41.748009Z",
          "shell.execute_reply": "2022-05-02T12:21:41.747353Z",
          "shell.execute_reply.started": "2022-05-02T12:21:41.739081Z"
        },
        "id": "uKizbe0inE46",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=config.target_sample_rate,\n",
        "                                                      n_fft=config.n_fft, \n",
        "                                                      hop_length=config.hop_length, \n",
        "                                                      n_mels=config.n_mels)\n",
        "\n",
        "\n",
        "test_clean = clean_wavs_path[:10]\n",
        "test_noisy = noisy_wavs_path[:10]\n",
        "\n",
        "training_dataset = CustomDataset(clean_wavs_path[10:2000], noisy_wavs_path[10:2000], mel_spectrogram)\n",
        "validation_dataset = CustomDataset(clean_wavs_path[2000:], noisy_wavs_path[2000:], mel_spectrogram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:41.983429Z",
          "iopub.status.busy": "2022-05-02T12:21:41.982376Z",
          "iopub.status.idle": "2022-05-02T12:21:41.989064Z",
          "shell.execute_reply": "2022-05-02T12:21:41.987894Z",
          "shell.execute_reply.started": "2022-05-02T12:21:41.983379Z"
        },
        "id": "C4t37a16nE4_",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainloader size:  16\n",
            "Validloader size:  5\n"
          ]
        }
      ],
      "source": [
        "trainloader = DataLoader(training_dataset, batch_size=config.batch_size)\n",
        "# print trainloader size\n",
        "print('Trainloader size: ', len(trainloader))\n",
        "validloader = DataLoader(validation_dataset, batch_size=config.batch_size)\n",
        "# print validloader size\n",
        "print('Validloader size: ', len(validloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:43.586575Z",
          "iopub.status.busy": "2022-05-02T12:21:43.586328Z",
          "iopub.status.idle": "2022-05-02T12:21:43.897858Z",
          "shell.execute_reply": "2022-05-02T12:21:43.896949Z",
          "shell.execute_reply.started": "2022-05-02T12:21:43.586543Z"
        },
        "id": "QP-JhGaUnE5D",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x900 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "a = iter(trainloader)\n",
        "images = a._next_data()\n",
        "\n",
        "\n",
        "def imageshow_ax(image, ax):\n",
        "    npimage = image.numpy()\n",
        "    ax.imshow(np.transpose(npimage, (1, 2, 0)))\n",
        "\n",
        "plt.figure(figsize=(15, 9))\n",
        "fig, axs = plt.subplots(1, 2)\n",
        "\n",
        "for image_number, ax in enumerate(axs.ravel()):\n",
        "    imageshow_ax(torchvision.utils.make_grid(images[image_number][:4]), ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4cibISvnE5I"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-05-02T12:21:43.907314Z",
          "iopub.status.busy": "2022-05-02T12:21:43.907004Z",
          "iopub.status.idle": "2022-05-02T12:21:43.998497Z",
          "shell.execute_reply": "2022-05-02T12:21:43.997619Z",
          "shell.execute_reply.started": "2022-05-02T12:21:43.907272Z"
        },
        "id": "IZ-ZI0z9nE5L",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class UNetGenerator(nn.Module):\n",
        "    def __init__(self, chnls_in=1, chnls_out=1):\n",
        "        super(UNetGenerator, self).__init__()\n",
        "        self.down_conv_layer_1 = DownConvBlock(chnls_in, 64, norm=False)\n",
        "        self.down_conv_layer_2 = DownConvBlock(64, 128)\n",
        "        self.down_conv_layer_3 = DownConvBlock(128, 256)\n",
        "        self.down_conv_layer_4 = DownConvBlock(256, 256, dropout=0.5)\n",
        "        self.down_conv_layer_5 = DownConvBlock(256, 256, dropout=0.5)\n",
        "        self.down_conv_layer_6 = DownConvBlock(256, 256, dropout=0.5)\n",
        "\n",
        "        self.up_conv_layer_1 = UpConvBlock(256, 256, kernel_size=(2,3), stride=2, padding=0, dropout=0.5)# 256+256 6 5 kernel_size=(2, 3), stride=2, padding=0\n",
        "        self.up_conv_layer_2 = UpConvBlock(512, 256, kernel_size=(2,3), stride=2, padding=0, dropout=0.5) # 256+256 1 4\n",
        "        self.up_conv_layer_3 = UpConvBlock(512, 256, kernel_size=(2,3), stride=2, padding=0, dropout=0.5) # 2 3\n",
        "        self.up_conv_layer_4 = UpConvBlock(512, 128, dropout=0.5) # 3 2\n",
        "        self.up_conv_layer_5 = UpConvBlock(256, 64) # 4 1\n",
        "        self.up_conv_layer_6 = UpConvBlock(512, 128)\n",
        "        self.up_conv_layer_7 = UpConvBlock(256, 64)\n",
        "        self.upsample_layer = nn.Upsample(scale_factor=2)\n",
        "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0))\n",
        "        self.conv_layer_1 = nn.Conv2d(128, chnls_out, 4, padding=1)\n",
        "        self.activation = nn.Tanh()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        #print('x', x.shape)\n",
        "        enc1 = self.down_conv_layer_1(x) # [4, 64, 32, 188]\n",
        "        print('1', enc1.shape)\n",
        "        enc2 = self.down_conv_layer_2(enc1) # [4, 128, 16, 94]\n",
        "        print('2', enc2.shape)\n",
        "        enc3 = self.down_conv_layer_3(enc2) # [4, 256, 8, 47]\n",
        "        print('3', enc3.shape)\n",
        "        enc4 = self.down_conv_layer_4(enc3) # [4, 256, 4, 23]\n",
        "        print('4', enc4.shape)\n",
        "        enc5 = self.down_conv_layer_5(enc4) # [4, 256, 2, 11]\n",
        "        print('5', enc5.shape)\n",
        "        enc6 = self.down_conv_layer_6(enc5) # [4, 256, 1, 5]\n",
        "        #print('6', enc6.shape)\n",
        " \n",
        "        dec1 = self.up_conv_layer_1(enc6, enc5)# enc6: 256 + enc5: 256 [4, 512, 2, 11]\n",
        "        #print('d1', dec1.shape)\n",
        "        dec2 = self.up_conv_layer_2(dec1, enc4)# enc4: 256 + dec1=enc5*2: [4, 512, 4, 23]\n",
        "        #print('d2', dec2.shape)\n",
        "        dec3 = self.up_conv_layer_3(dec2, enc3)# enc3: 256 + dec2=enc4*2: [4, 512, 8, 47]\n",
        "        #print('d3', dec3.shape)\n",
        "        dec4 = self.up_conv_layer_4(dec3, enc2)# enc2: 128 + dec3=enc3*2: [4, 256, 16, 94]\n",
        "        #print('d4', dec4.shape)\n",
        "        dec5 = self.up_conv_layer_5(dec4, enc1)# enc1: 64 + dec4=enc1*2: [4, 128, 32, 188]\n",
        "        #print('d5', dec5.shape)\n",
        "      \n",
        "        final = self.upsample_layer(dec5)\n",
        "        final = self.zero_pad(final)\n",
        "        final = self.conv_layer_1(final)\n",
        "        #print(final.shape)\n",
        "        return final\n",
        "\n",
        "class UpConvBlock(nn.Module):\n",
        "    def __init__(self, ip_sz, op_sz, kernel_size=4, stride= 2, padding=1 ,dropout=0.0):\n",
        "        super(UpConvBlock, self).__init__()\n",
        "        self.layers = [\n",
        "            nn.ConvTranspose2d(ip_sz, op_sz, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "            nn.InstanceNorm2d(op_sz),\n",
        "            nn.ReLU(),\n",
        "        ]\n",
        "        if dropout:\n",
        "            self.layers += [nn.Dropout(dropout)]\n",
        "    def forward(self, x, enc_ip):\n",
        "        x = nn.Sequential(*(self.layers))(x)\n",
        "        #print('x', x.shape)\n",
        "        #print('enc', enc_ip.shape)\n",
        "        op = torch.cat((x, enc_ip), 1)\n",
        "        return op\n",
        "\n",
        "\n",
        "class DownConvBlock(nn.Module):\n",
        "    def __init__(self, ip_sz, op_sz, kernel_size=4, norm=True, dropout=0.0):\n",
        "        super(DownConvBlock, self).__init__()\n",
        "        self.layers = [nn.Conv2d(ip_sz, op_sz, kernel_size, 2, 1)]\n",
        "        if norm:\n",
        "            self.layers.append(nn.InstanceNorm2d(op_sz))\n",
        "        self.layers += [nn.LeakyReLU(0.2)]\n",
        "        if dropout:\n",
        "            self.layers += [nn.Dropout(dropout)]\n",
        "    def forward(self, x):\n",
        "        op = nn.Sequential(*(self.layers))(x)\n",
        "        return op\n",
        "    \n",
        "model = UNetGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T10:04:10.785623Z",
          "iopub.status.busy": "2022-04-27T10:04:10.785142Z",
          "iopub.status.idle": "2022-04-27T10:04:10.799833Z",
          "shell.execute_reply": "2022-04-27T10:04:10.79874Z",
          "shell.execute_reply.started": "2022-04-27T10:04:10.785507Z"
        },
        "id": "wTo6fGeenE5N",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(dataloader, model, epoch, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for i, (clean, noisy) in enumerate(tqdm(dataloader)):\n",
        "        clean = clean.to(device)\n",
        "        noisy = noisy.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = model(noisy)\n",
        "        curr_loss = loss_fn(pred, clean)\n",
        "        curr_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += curr_loss\n",
        "        if i % 1000 == 0:\n",
        "            print('[Epoch number : %d, Mini-batches: %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, total_loss / 200))\n",
        "            total_loss = 0.0\n",
        "            \n",
        "def val(dataloader, model, epoch, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    print('-------------------------')\n",
        "    with torch.no_grad():\n",
        "        for i, (clean, noisy) in enumerate(tqdm(dataloader)):\n",
        "            clean = clean.to(device)\n",
        "            noisy = noisy.to(device)\n",
        "        \n",
        "            output = model(noisy)\n",
        "            loss = loss_fn(output, clean)\n",
        "            total_loss += loss\n",
        "            if i % 100 == 0:\n",
        "                print('[Valid Epoch number : %d, Mini-batches: %5d] loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, total_loss / 200))\n",
        "                total_loss = 0.0\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T10:04:10.802266Z",
          "iopub.status.busy": "2022-04-27T10:04:10.801778Z",
          "iopub.status.idle": "2022-04-27T14:22:29.842528Z",
          "shell.execute_reply": "2022-04-27T14:22:29.838683Z",
          "shell.execute_reply.started": "2022-04-27T10:04:10.802218Z"
        },
        "id": "0_1AJeyHnE5P",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/16 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [48], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[39m=\u001b[39m UNetGenerator()\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(config\u001b[39m.\u001b[39mepochs):\n\u001b[0;32m---> 11\u001b[0m     train(trainloader, model, epoch, loss_fn, optimizer, device)\n\u001b[1;32m     12\u001b[0m     val(validloader, model, epoch, loss_fn, device)\n",
            "Cell \u001b[0;32mIn [47], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, epoch, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m noisy \u001b[39m=\u001b[39m noisy\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m pred \u001b[39m=\u001b[39m model(noisy)\n\u001b[1;32m     12\u001b[0m curr_loss \u001b[39m=\u001b[39m loss_fn(pred, clean)\n\u001b[1;32m     13\u001b[0m curr_loss\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn [46], line 28\u001b[0m, in \u001b[0;36mUNetGenerator.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     27\u001b[0m     \u001b[39m#print('x', x.shape)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     enc1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_conv_layer_1(x) \u001b[39m# [4, 64, 32, 188]\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m, enc1\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     30\u001b[0m     enc2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_conv_layer_2(enc1) \u001b[39m# [4, 128, 16, 94]\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "Cell \u001b[0;32mIn [46], line 86\u001b[0m, in \u001b[0;36mDownConvBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 86\u001b[0m     op \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mSequential(\u001b[39m*\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers))(x)\n\u001b[1;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m op\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "loss_fn = torch.nn.functional.mse_loss\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = UNetGenerator().cuda()\n",
        "\n",
        "for epoch in range(config.epochs):\n",
        "    train(trainloader, model, epoch, loss_fn, optimizer, device)\n",
        "    val(validloader, model, epoch, loss_fn, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-04-27T14:25:48.573982Z",
          "iopub.status.busy": "2022-04-27T14:25:48.573643Z",
          "iopub.status.idle": "2022-04-27T14:25:48.622417Z",
          "shell.execute_reply": "2022-04-27T14:25:48.621329Z",
          "shell.execute_reply.started": "2022-04-27T14:25:48.573945Z"
        },
        "id": "8jWEH9bKnE5R",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PATH = './working/model'\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "audo-denoising.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
